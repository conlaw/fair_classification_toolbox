{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.insert(0, '../fair-classification/fair_classification/') # the code for fair classification is in this directory\n",
    "import utils as ut\n",
    "import funcs_disp_mist as fdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for computing fairness/accuracy\n",
    "def compute_TPR_GAP(preds, Y, group):\n",
    "    res = {}\n",
    "    res['TPR'] = sum(preds[Y])/len(preds[Y])\n",
    "    res['TPR_1'] = sum(preds[Y & group])/len(preds[Y & group])\n",
    "    res['TPR_2'] = sum(preds[Y & ~group])/len(preds[Y & ~group])\n",
    "    res['TPR_GAP'] = abs(res['TPR_1'] - res['TPR_2'])\n",
    "    return res\n",
    "\n",
    "def compute_TNR_GAP(preds, Y, group):\n",
    "    res = {}\n",
    "    res['TNR'] = sum(~preds[~Y])/len(preds[~Y])\n",
    "    res['TNR_1'] = sum(~preds[~Y & group])/len(preds[~Y & group])\n",
    "    res['TNR_2'] = sum(~preds[~Y & ~group])/len(preds[~Y & ~group])\n",
    "    res['TNR_GAP'] = abs(res['TNR_1'] - res['TNR_2'])\n",
    "    return res\n",
    "\n",
    "def compute_ACC_GAP(preds, Y, group):\n",
    "    res = {}\n",
    "    res['ACC'] = sum(preds == Y)/len(Y)\n",
    "    res['ACC_1'] = sum(preds[group] == Y[group])/len(Y[group])\n",
    "    res['ACC_2'] = sum(preds[~group] == Y[~group])/len(Y[~group])\n",
    "    res['ACC_GAP'] = abs(res['ACC_1'] - res['ACC_2'])\n",
    "    return res\n",
    "    \n",
    "def compute_EqOpp(preds, Y, group):\n",
    "    return compute_TPR_GAP(preds, Y, group)\n",
    "\n",
    "def compute_EqOd(preds, Y, group):\n",
    "    return compute_TPR_GAP(preds, Y, group).update(compute_TNR_GAP(preds, Y, group) )\n",
    "\n",
    "def compute_AccDisp(preds, Y, group):\n",
    "    return compute_ACC_GAP(preds, Y, group)\n",
    "\n",
    "def compute_fairness(predss,Y,group):\n",
    "    res = compute_TPR_GAP(preds, Y, group)\n",
    "    res.update(compute_TNR_GAP(preds, Y, group))\n",
    "    res.update(compute_ACC_GAP(preds,Y,group))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equalized Odds\n",
    "results = []\n",
    "datasets = ['adult','default','compas']\n",
    "protected_features = {'compas': 'race', \n",
    "                      'adult': 'gender',\n",
    "                      'default': 'X2'\n",
    "                     }\n",
    "\n",
    "tau_dict = {'compas': 5,\n",
    "       'adult': 20,\n",
    "       'default': 0.05\n",
    "      }\n",
    "\n",
    "fairness_metrics = ['EqualizedOdds', 'EqOp']\n",
    "\n",
    "for dataset in datasets:\n",
    "    print('**** DATASET %s ******'%dataset)\n",
    "    group_var = protected_features[dataset]\n",
    "    for i in range(10):\n",
    "        print('***** FOLD %d ******'%i)\n",
    "        train  = pd.read_csv('split_data/'+dataset+'_train_%d.csv'%i).assign(train = True)\n",
    "        test = pd.read_csv('split_data/'+dataset+'_test_%d.csv'%i).assign(train = False)\n",
    "        \n",
    "        full = pd.get_dummies(train.append(test))\n",
    "        \n",
    "        train = full.query('train').drop('train',axis=1)\n",
    "        test = full.query('train == False').drop('train',axis=1)\n",
    "\n",
    "        for fairMet in fairness_metrics:\n",
    "            for eps in np.concatenate([np.linspace(0,1,10),[1]]):\n",
    "                for hp in [1]:\n",
    "                    print('Tau: %f'%hp)\n",
    "                    \n",
    "                    if fairMet == 'EqualizedOdds':\n",
    "                        constraint = 4\n",
    "                    elif fairMet == 'EqOp':\n",
    "                        constraint = 2\n",
    "                                        \n",
    "                    \n",
    "                    cons_type = constraint \n",
    "                    tau = tau_dict[dataset]\n",
    "                    mu = 1.2\n",
    "                    sensitive_attrs_to_cov_thresh = {group_var: {0:{0:0, 1:eps}, 1:{0:0, 1:eps}, 2:{0:0, 1:eps}}} # zero covariance threshold, means try to get the fairest solution\n",
    "                    cons_params = {\"cons_type\": cons_type, \n",
    "                                   \"tau\": tau, \n",
    "                                   \"mu\": mu, \n",
    "                                   \"sensitive_attrs_to_cov_thresh\": sensitive_attrs_to_cov_thresh}\n",
    "                    \n",
    "                    try:\n",
    "                        start_time = time.time()\n",
    "                        w= fdm.train_model_disp_mist(train.drop('Y',axis=1).to_numpy(), \n",
    "                          train['Y'].to_numpy()*2 - 1, \n",
    "                          {group_var: train[group_var].astype(np.int).to_numpy()}, \n",
    "                          \"logreg\", 1e-6, cons_params=cons_params)\n",
    "\n",
    "                        end_time = time.time() - start_time\n",
    "\n",
    "                        preds = (np.sign(fdm.get_distance_boundary(w, \n",
    "                                                                  test.drop('Y',axis=1).to_numpy(), \n",
    "                                                                  test[group_var].astype(np.int).to_numpy())))\n",
    "                        preds = (preds/2+0.5).astype(np.bool)\n",
    "\n",
    "                        y = test['Y'].to_numpy()\n",
    "                        group = test[group_var].to_numpy()\n",
    "\n",
    "                        res = compute_fairness(preds, y, group)\n",
    "                        res['fold'] = i\n",
    "                        res['fairnessCriteria'] = fairMet\n",
    "                        res['algo'] = 'zafar17'\n",
    "                        res['eps'] = eps\n",
    "                        res['data_set'] = dataset\n",
    "                        res['train_time'] = end_time\n",
    "                        results.append(res)\n",
    "                    except:\n",
    "                        print('failed')\n",
    "                        continue\n",
    "pd.DataFrame.from_records(results).to_csv('zafar_results_jan21.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
